#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DBF Sync Agent
–ê–≥–µ–Ω—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ DBF —Ñ–∞–π–ª–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä

–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –ü–ö –º–∞–≥–∞–∑–∏–Ω–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ tov.dbf,
–æ—Ç–ø—Ä–∞–≤–ª—è—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python agent.py

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
    pip install watchdog requests

–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
    –°–æ–∑–¥–∞–π—Ç–µ config.json —Ä—è–¥–æ–º —Å agent.py (—Å–º. config.example.json)
"""

import os
import sys
import json
import time
import struct
import logging
import requests
from datetime import datetime
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('sync.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
CONFIG_FILE = Path(__file__).parent / 'config.json'

# –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
DEFAULT_CONFIG = {
    'shopId': 'shop_1',
    'shopName': '–ú–∞–≥–∞–∑–∏–Ω 1',
    'dbfPath': 'C:\\Database\\tov.dbf',
    'serverUrl': 'https://arabica26.ru',
    'apiKey': 'arabica-sync-2025',
    'syncIntervalSeconds': 60,
    'encoding': 'cp866',
    'fields': {
        'kod': 'KOD',
        'name': 'NAME',
        'group': '–ì–†–£–ü–ü–ê',
        'stock': '–û–°–¢'
    }
}


def load_config():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞"""
    if not CONFIG_FILE.exists():
        logger.warning(f'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {CONFIG_FILE}')
        logger.info('–ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é')
        return DEFAULT_CONFIG

    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
            # –ú–µ—Ä–¥–∂–∏–º —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            for key, value in DEFAULT_CONFIG.items():
                if key not in config:
                    config[key] = value
            return config
    except Exception as e:
        logger.error(f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}')
        return DEFAULT_CONFIG


def parse_dbf(dbf_path, encoding='cp866'):
    """
    –ü–∞—Ä—Å–∏–Ω–≥ DBF —Ñ–∞–π–ª–∞

    Args:
        dbf_path: –ü—É—Ç—å –∫ DBF —Ñ–∞–π–ª—É
        encoding: –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ (–æ–±—ã—á–Ω–æ cp866 –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)

    Returns:
        list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –∑–∞–ø–∏—Å–µ–π
    """
    records = []

    try:
        with open(dbf_path, 'rb') as f:
            # –ß–∏—Ç–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ DBF
            header = f.read(32)

            if len(header) < 32:
                logger.error('–§–∞–π–ª DBF —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π')
                return records

            # –ü–∞—Ä—Å–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            num_records = struct.unpack('<I', header[4:8])[0]
            header_size = struct.unpack('<H', header[8:10])[0]
            record_size = struct.unpack('<H', header[10:12])[0]

            logger.info(f'DBF: {num_records} –∑–∞–ø–∏—Å–µ–π, –∑–∞–≥–æ–ª–æ–≤–æ–∫ {header_size} –±–∞–π—Ç, –∑–∞–ø–∏—Å—å {record_size} –±–∞–π—Ç')

            # –ß–∏—Ç–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ–ª–µ–π
            fields = []
            f.seek(32)

            while True:
                field_header = f.read(32)
                if len(field_header) < 32 or field_header[0] == 0x0D:
                    break

                field_name = field_header[0:11].split(b'\x00')[0].decode('ascii', errors='ignore').strip()
                field_type = chr(field_header[11])
                field_size = field_header[16]

                fields.append({
                    'name': field_name,
                    'type': field_type,
                    'size': field_size
                })

            logger.info(f'DBF –ø–æ–ª–µ–π: {len(fields)}')

            # –ß–∏—Ç–∞–µ–º –∑–∞–ø–∏—Å–∏
            f.seek(header_size)

            for i in range(num_records):
                record_data = f.read(record_size)

                if len(record_data) < record_size:
                    break

                # –ü–µ—Ä–≤—ã–π –±–∞–π—Ç - —Ñ–ª–∞–≥ —É–¥–∞–ª–µ–Ω–∏—è
                if record_data[0] == 0x2A:  # '*' = deleted
                    continue

                record = {}
                offset = 1  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∞–π—Ç —É–¥–∞–ª–µ–Ω–∏—è

                for field in fields:
                    value = record_data[offset:offset + field['size']]

                    try:
                        value = value.decode(encoding, errors='ignore').strip()
                    except:
                        value = value.decode('latin-1', errors='ignore').strip()

                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è
                    if field['type'] == 'N':
                        try:
                            if '.' in value:
                                value = float(value) if value else 0.0
                            else:
                                value = int(value) if value else 0
                        except:
                            value = 0

                    record[field['name']] = value
                    offset += field['size']

                records.append(record)

            logger.info(f'DBF: –ø—Ä–æ—á–∏—Ç–∞–Ω–æ {len(records)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π')

    except FileNotFoundError:
        logger.error(f'–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {dbf_path}')
    except Exception as e:
        logger.error(f'–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ DBF: {e}')

    return records


def extract_products(records, config):
    """
    –ò–∑–≤–ª–µ—á—å —Ç–æ–≤–∞—Ä—ã –∏–∑ –∑–∞–ø–∏—Å–µ–π DBF –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º –ø–æ–ª—è–º

    Args:
        records: –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –∏–∑ DBF
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

    Returns:
        list: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è API
    """
    products = []
    field_mapping = config.get('fields', DEFAULT_CONFIG['fields'])

    kod_field = field_mapping.get('kod', 'KOD')
    name_field = field_mapping.get('name', 'NAME')
    group_field = field_mapping.get('group', '–ì–†–£–ü–ü–ê')
    stock_field = field_mapping.get('stock', '–û–°–¢')

    for record in records:
        kod = str(record.get(kod_field, '')).strip()
        name = str(record.get(name_field, '')).strip()
        group = str(record.get(group_field, '')).strip()
        stock = record.get(stock_field, 0)

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∫–æ–¥–∞ –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—è
        if not kod or not name:
            continue

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –≤ —á–∏—Å–ª–æ
        if isinstance(stock, str):
            try:
                stock = float(stock.replace(',', '.'))
            except:
                stock = 0

        products.append({
            'kod': kod,
            'name': name,
            'group': group,
            'stock': int(stock)
        })

    return products


def sync_to_server(products, config):
    """
    –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä

    Args:
        products: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

    Returns:
        bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
    """
    server_url = config['serverUrl'].rstrip('/')
    shop_id = config['shopId']
    api_key = config['apiKey']

    url = f'{server_url}/api/shop-products/{shop_id}/sync'

    try:
        response = requests.post(
            url,
            json={'products': products},
            headers={
                'Content-Type': 'application/json',
                'X-API-Key': api_key
            },
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            logger.info(f'‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: {result.get("productCount", 0)} —Ç–æ–≤–∞—Ä–æ–≤')
            return True
        elif response.status_code == 401:
            logger.error('‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á')
            return False
        else:
            logger.error(f'‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {response.status_code} - {response.text}')
            return False

    except requests.exceptions.Timeout:
        logger.error('‚ùå –¢–∞–π–º–∞—É—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º')
        return False
    except requests.exceptions.ConnectionError:
        logger.error('‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É')
        return False
    except Exception as e:
        logger.error(f'‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}')
        return False


def get_file_mtime(path):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞"""
    try:
        return os.path.getmtime(path)
    except:
        return 0


def run_sync_loop(config):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏

    –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç —Ñ–∞–π–ª DBF –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä
    """
    dbf_path = config['dbfPath']
    interval = config.get('syncIntervalSeconds', 60)
    encoding = config.get('encoding', 'cp866')

    logger.info('=' * 50)
    logger.info(f'DBF Sync Agent v1.0')
    logger.info(f'–ú–∞–≥–∞–∑–∏–Ω: {config["shopName"]} ({config["shopId"]})')
    logger.info(f'DBF —Ñ–∞–π–ª: {dbf_path}')
    logger.info(f'–°–µ—Ä–≤–µ—Ä: {config["serverUrl"]}')
    logger.info(f'–ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval} —Å–µ–∫')
    logger.info('=' * 50)

    last_mtime = 0
    last_sync = 0

    while True:
        try:
            current_time = time.time()
            current_mtime = get_file_mtime(dbf_path)

            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –µ—Å–ª–∏:
            # 1. –§–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è
            # 2. –ò–ª–∏ –ø—Ä–æ—à–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            should_sync = False

            if current_mtime > last_mtime:
                logger.info(f'üìÅ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ DBF')
                should_sync = True
                last_mtime = current_mtime
            elif current_time - last_sync >= interval:
                logger.info(f'‚è∞ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è')
                should_sync = True

            if should_sync:
                # –ü–∞—Ä—Å–∏–º DBF
                records = parse_dbf(dbf_path, encoding)

                if records:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–≤–∞—Ä—ã
                    products = extract_products(records, config)
                    logger.info(f'üì¶ –ù–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤')

                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Å–µ—Ä–≤–µ—Ä
                    if products:
                        sync_to_server(products, config)
                        last_sync = current_time
                else:
                    logger.warning('‚ö†Ô∏è –ó–∞–ø–∏—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ DBF')

            # –ñ–¥—ë–º –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            time.sleep(5)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥

        except KeyboardInterrupt:
            logger.info('üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–≥–µ–Ω—Ç–∞...')
            break
        except Exception as e:
            logger.error(f'‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}')
            time.sleep(10)


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    logger.info('üöÄ –ó–∞–ø—É—Å–∫ DBF Sync Agent...')

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_config()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ DBF
    if not os.path.exists(config['dbfPath']):
        logger.error(f'‚ùå –§–∞–π–ª DBF –Ω–µ –Ω–∞–π–¥–µ–Ω: {config["dbfPath"]}')
        logger.info('–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –≤ config.json')
        sys.exit(1)

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
    run_sync_loop(config)


if __name__ == '__main__':
    main()
